---
title: "India GDP Project"
author: "Jay & Parker"
date: "2024-02-09"
output: html_document
---
# read in the India GDP File
```{r}
library(readxl)
IndiaGDP <- read_excel("India_GDP.xlsx", sheet = "Sheet1")

# plot the India GDP
# names(IndiaGDP)[1] <- "Year"
# names(IndiaGDP)[2] <- "GDP"
IndiaGDP_ts <-
  ts(
    IndiaGDP$GDP,
    start = c(1), # 1980
    end = c(44), # 2023
    frequency = 1
  )
t

# plot India GDP
plot(IndiaGDP_ts, type = "l", main = "India GDP: Meteoric Rise Post 2007", ylab = "GDP in Billions, USD ($)", xlab = "Year", lwd = 2, col = "darkorange")
# change the x-axis and y-axis labels

```

# Detrend The Model
```{r}
library(forecast)

# got rid of the forecasts 2024-2028 (5 years)
IndiaGDP <- IndiaGDP[-c(45, 46, 47, 48, 49),]

# clear evidence of cycles
# detrend for cyclical too
# make a t variable to track the row number of the IndiaGDP data frame
t <- 1:nrow(IndiaGDP)
IndiaGDP$t <- t
cyc1 <- sin((2 * pi * t) / 44)
cyc2 <- cos((2 * pi * t) / 44)
# a half cycle is about 22 years, so the whole cycle would be 44 years
# determined 22 after looking at the residuals
```


## Data Partitioning
```{r}
# partition the data - 41 years training, 3 years validation
# change this based on pred year
train.ts <- window(IndiaGDP_ts, start = c(1), end = c(39)) # 1980, 2018
valid.ts <- window(IndiaGDP_ts, start = c(2019), end = c(2023))
# we wanted COVID to be present in both training and validation sets
# justify why you choose your training period
# it must be representative of the circumstances of the forecast horizon

# detrend on train
DTGDP <- tslm(train.ts ~ I(trend ^ 2) + cyc2[1:39])
summary(DTGDP)

# detrend on cubic and cycle2
DTGDP_cubic_cyc2 <- tslm(train.ts ~ I(trend ^ 3) + cyc2[1:39])
summary(DTGDP_cubic_cyc2)

# detrend for linear
DTGDP_linear <- tslm(train.ts ~ trend)
summary(DTGDP_linear) # R^2 = 0.8266 and ***

# detrend for quadratic
DTGDP_quad <- tslm(train.ts ~ I(trend ^ 2))
summary(DTGDP_quad) # R^2 = 0.9566 and ***

# detrend for cubic
DTGDP_cubic <- tslm(train.ts ~ I(trend ^ 3))
summary(DTGDP_cubic) # R^2 = 0.9824 and ***

# detrend for cycles
DTGDP_cyc <- tslm(train.ts ~ cyc1[1:39] + cyc2[1:39])
summary(DTGDP_cyc) # R^2 = 0.7323 and both cycles are ***

# detrend for cubic and linear
DTGDP_cubic_linear <- tslm(train.ts ~ I(trend ^ 3) + trend)
summary(DTGDP_cubic_linear) # R^2 = 0.9824. Cubic is *** and linear is not sig

# detrend for cubic and quadratic
DTGDP_cubic_quad <- tslm(train.ts ~ I(trend ^ 3) + I(trend ^ 2))
summary(DTGDP_cubic_quad) # R^2 = 0.9824. Cubic is `***` and quadratic is not sig

# detrend for cubic and cycles
DTGDP_cubic_cyc <- tslm(train.ts ~ I(trend ^ 3) + cyc1[1:39] + cyc2[1:39])
summary(DTGDP_cubic_cyc) # R^2 = 0.985. Cubic is *** and both cycles are *

# detrend for quadratic and both cycles
DTGDP_quad_cyc <- tslm(train.ts ~ I(trend ^ 2) + cyc1[1:39] + cyc2[1:39])
summary(DTGDP_quad_cyc) # R^2 = . Quadratic is *** and cyc2 is *** for 2021
# cyc1 not significant

# most parsimonious is just cubic

# plot residuals for just cubic
# plot(DTGDP_cubic$residuals, type = "l")

# plot residuals for cubic and cycles
plot(DTGDP_cubic_cyc$residuals, type = "l", main = "Residuals of Cubic and Both Cycles Model", ylab = "Residuals", xlab = "Year", lwd = 2, col = "darkorange")

# plot residuals for DTGDP
plot(DTGDP$residuals, type = "l", main = "Residuals of Quadratic + Cycle2 Model", ylab = "Residuals", xlab = "Year", lwd = 2, col = "darkorange")

# cubic is better

# test for autocorrelation
library(car)
# autocorrelation
durbinWatsonTest(DTGDP)
# lag Autocorrelation D-W Statistic p-value
#   1       0.5778103     0.8111599   0.014
# Alternative hypothesis: rho != 0
# there is autocorrelation

# store residuals - MAKE SURE THIS IS USING THE BEST MODEL based on R^2
DTGDP_cubic_resids <- DTGDP$residuals

# Check ACF PACF of residuals
par(mfrow = c(1, 2))
A = Acf(DTGDP_cubic_resids, main = "ACF of Residuals")
A
B = Pacf(DTGDP_cubic_resids, main = "PACF of Residuals")
B

# We have an AR(1) component, an MA(1) component, and a MA(8) component
ARMA1_DT <- Arima(DTGDP_cubic_resids, order = c(1, 0, 0))
summary(ARMA1_DT)

# check for significance
0.5825 / 0.1284
# greater than 2 so it is significant

# get and plot the residuals
ARMA1_resids <- ARMA1_DT$residuals
plot(ARMA1_resids, type = "l")

par(mfrow = c(1, 2))
A = Acf(ARMA1_resids, main = "ACF of Residuals")
A
B = Pacf(ARMA1_resids, main = "PACF of Residuals")
B

# All components have been removed
# Removing AR(1) took care of the MA(1) and MA(8)

# We can now forecast
```

Neural Network
```{r}
library(neuralnet)
library(dplyr)
library(caret)

setup1 <- nnetar(IndiaGDP_ts[1:39],
                 p = 12,
                 repeats = 20,
                 lambda = "auto")

#Once the model is set up, we forecast. PI - prediction intervals
Fcast <- forecast(setup1, PI = TRUE, h = 5)
#Show results
autoplot(Fcast)
```


Prediction for 2024
```{r}
gdp2023.residual <-
  window(DTGDP_cubic_resids, start = c(2022), end = c(2022))

plugin.forecast <-
  gdp2023.residual * ARMA1_DT$coef[1] + ARMA1_DT$coef[2]

print(plugin.forecast)
```

```{r}
# ENSURE THE DENOMINATOR I.E. 40 or whatever matches what is up top
# change this to match pred year - 1
gdp2023.residual <-
  window(DTGDP_cubic_resids, start = c(1980), end = c(2022))

t <- length(gdp2023.residual) + 1

# check this for best model R^2 and make sure it matches
forecasted.value <- DTGDP$coefficients[1] + DTGDP$coefficients[2] * (t ^ 2) + DTGDP$coefficients[3] * cos((2 * pi * t) / 44)

forecasted.value
```


```{r}
plugin.forecast + forecasted.value
```

Future
```{r}
# Extend the time variable 't' for forecasting
future_t <-
  (max(IndiaGDP$t) + 1):(max(IndiaGDP$t) + 11)  # For 2024-2034

# Calculate future cyclical components based on future_t
future_cyc2 <- cos((2 * pi * future_t) / 44)

# Forecast GDP using the DTGDP model coefficients
# Assuming the model is of the form: GDP ~ I(trend ^ 2) + cyc2
# Adjust the coefficients indexing based on your actual model summary
future_gdp_forecast <- DTGDP$coefficients[1] +
  DTGDP$coefficients[2] * (future_t ^ 2) +
  DTGDP$coefficients[3] * future_cyc2

# Print the forecasted GDP values
print(future_gdp_forecast)


# throw these numbers in a data frame. Add a new column for year beginning with 2024
future_gdp_forecast_df <- data.frame(
  Year = 2024:2034,
  Forecasted_GDP = future_gdp_forecast
)
```

This is a conservative prediction because we have signs of overfitting in the model which could lead to underestimation of the GDP. This is what it should be and show the statista. We hope for an exponential. 

Based on historical data there is no clear evidence of an outright exponential spike. However, due to external information and jobs and other indicators [look up], that is what should contribute to the spike.

Our model is not doing that because you cannot predict GDP off of GDP itself.

Cite the paper no matter how useless.


Fitted values, plot neural network on the detrended data


```{r}
# plot the residuals of DTGDP and forecast using neural network

setup2 <- nnetar(DTGDP$residuals[1:39],
                 p = 12,
                 repeats = 20,
                 lambda = "auto")

#Once the model is set up, we forecast. PI - prediction intervals
Fcast2 <- forecast(setup2, PI = TRUE, h = 5)
#Show results
autoplot(Fcast2)
```

Assessing the Fitted Model

```{r}
Actual <- IndiaGDP_ts[40:44]
Nnet_actual <- Fcast$mean
Nnet_actual_MAPE <- mean(abs(Actual - Nnet_actual) / Actual)
Nnet_actual_MAPE

Actual1 <- valid.ts[1:5]
Nnet_DT <- Fcast2$mean
Nnet_DT_MAPE <- mean(abs(Actual1 - Nnet_DT) / Actual1)
Nnet_DT_MAPE
```

India TS Neural Net - showing the fitted/how it fits

```{r}
par(mfrow = c(1, 1))
plot(
  IndiaGDP_ts,
  ylim = c(150, 4000),
  ylab = "India GDP",
  xlab = "Year",
  type = "l",
  xaxt = "n",
  xlim = c(1, 44),
  main = "",
  lty = 2
)
axis(1, at = seq(1, 44, 1), labels = format(seq(1, 44, 1)))
lines(Fcast$mean, col = "blue")
lines(Fcast$fitted, col = "red")
lines(c(40, 40), c(150, 4000))
lines(c(44, 44), c(150, 4000))
legend(
  "topleft",
  inset = c(0, 0),
  legend = c(
    "Neural Network Forecast - mean value",
    "Actual",
    "Fitted to Training data"
  ),
  col = c("black", "blue", "red"),
  pch = 1,
  cex = 0.5
)
```

Same thing for DT

```{r}
plot(
  DTGDP$residuals,
  ylim = c(-150, 200),
  ylab = "Milk",
  xlab = "Time",
  type = "l",
  xaxt = "n",
  xlim = c(1, 44),
  main = "",
  lty = 2
)
axis(1, at = seq(1, 44, 1), labels = format(seq(1, 44, 1)))
lines(Fcast2$mean, col = "blue")
lines(Fcast2$fitted, col = "red")
lines(c(40, 40), c(-300, 300))
lines(c(44, 44), c(-300, 300))
legend(
  "topleft",
  inset = c(0, 0),
  legend = c(
    "Neural Network Forecast - mean value",
    "Actual",
    "Fitted to Training data"
  ),
  col = c("black", "blue", "red"),
  pch = 1,
  cex = 0.5
)
```



